{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DineshGujjeti/Infosys_Springboard_CodeGenie/blob/main/Milestone2/code/milestone2_code_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Dependencies**"
      ],
      "metadata": {
        "id": "N-T1ALVL-u-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZmHmm5oU8I"
      },
      "outputs": [],
      "source": [
        "# @title Phase 1: Install Dependencies\n",
        "!pip install transformers torch accelerate bitsandbytes pandas huggingface_hub radon ipywidgets matplotlib seaborn -q\n",
        "\n",
        "\n",
        "# @title Phase 2: Imports and Hugging Face Login\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from huggingface_hub import notebook_login\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from radon.complexity import cc_visit\n",
        "from radon.metrics import mi_visit\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "from IPython.display import display, HTML\n",
        "import io\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import ast\n",
        "import seaborn as sns\n",
        "from radon.raw import analyze\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Secure Hugging Face Login**"
      ],
      "metadata": {
        "id": "6Jm5p3b2-3VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "0BEYPlScr8BX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration & Backend Engine**"
      ],
      "metadata": {
        "id": "9v9Jzh9u_A_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Configuration ---\n",
        "MODELS_TO_TEST = {\n",
        "    \"DeepSeek-Coder-1.3B\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
        "    \"Phi-2-2.7B\": \"microsoft/phi-2\",\n",
        "    \"Gemma-2B-IT\": \"google/gemma-2b-it\",\n",
        "    \"Stable-Code-3B\": \"stabilityai/stable-code-3b\",      # Added\n",
        "    \"Replit-Code-3B\": \"replit/replit-code-v1-3b\",        # Added\n",
        "}\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Helper & Generation Functions ---\n",
        "def clean_generated_code(text, model_path):\n",
        "    model_path = model_path.lower()\n",
        "    if \"gemma\" in model_path:\n",
        "        text = re.sub(r\"<start_of_turn>user\\n.*<end_of_turn>\\n<start_of_turn>model\\n\", \"\", text, flags=re.DOTALL).replace(\"<end_of_turn>\", \"\")\n",
        "    elif \"phi-2\" in model_path:\n",
        "        text = re.sub(r\"Instruct:.*\\nOutput:\", \"\", text, flags=re.DOTALL)\n",
        "    elif \"stable-code\" in model_path or \"replit\" in model_path:\n",
        "        text = re.sub(r\"### Instruction:\\n.*\\n\\n### Response:\", \"\", text, flags=re.DOTALL)\n",
        "    else:\n",
        "        text = re.sub(r\"### Instruction:\\n.*\\n\\n### Response:\", \"\", text, flags=re.DOTALL)\n",
        "    match = re.search(r\"``````\", text, re.DOTALL)\n",
        "    if match:\n",
        "        text = match.group(1)\n",
        "    return text.strip()\n",
        "\n",
        "def is_syntactically_valid(code_string: str) -> bool:\n",
        "    if not code_string:\n",
        "        return False\n",
        "    try:\n",
        "        ast.parse(code_string)\n",
        "        return True\n",
        "    except SyntaxError:\n",
        "        return False\n",
        "\n",
        "def calculate_advanced_metrics(code_string):\n",
        "    if not is_syntactically_valid(code_string):\n",
        "        return {\"complexity\": None, \"maintainability\": None, \"loc\": None}\n",
        "    try:\n",
        "        complexity = sum([c.complexity for c in cc_visit(code_string)]) if cc_visit(code_string) else 0\n",
        "        maintainability = mi_visit(code_string, multi=True)\n",
        "        loc = analyze(code_string).loc\n",
        "        return {\"complexity\": complexity, \"maintainability\": round(float(maintainability), 2), \"loc\": loc}\n",
        "    except:\n",
        "        return {\"complexity\": None, \"maintainability\": None, \"loc\": None}\n",
        "\n",
        "def generate_code(model, tokenizer, prompt):\n",
        "    model_path = model.name_or_path.lower()\n",
        "    if \"gemma\" in model_path:\n",
        "        formatted_prompt = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "    elif \"phi-2\" in model_path:\n",
        "        formatted_prompt = f\"Instruct: {prompt}\\nOutput:\"\n",
        "    elif \"stable-code\" in model_path or \"replit\" in model_path:\n",
        "        formatted_prompt = f\"### Instruction:\\n{prompt}\\n\\n### Response:\"\n",
        "    else:\n",
        "        formatted_prompt = f\"### Instruction:\\n{prompt}\\n\\n### Response:\"\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", return_attention_mask=True).to(device)\n",
        "    start_time = time.time()\n",
        "    output_ids = model.generate(\n",
        "        inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.1,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    raw_output = tokenizer.batch_decode(output_ids)[0]\n",
        "    cleaned_code = clean_generated_code(raw_output, model_path)\n",
        "\n",
        "    return {\"code\": cleaned_code, \"gen_time\": end_time - start_time}\n",
        "\n",
        "print(\"Backend engine with advanced metrics is ready.\")\n"
      ],
      "metadata": {
        "id": "oesUucnasP7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Loading All Models**"
      ],
      "metadata": {
        "id": "-uXFc2tg_Jp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Section 4: Pre-Loading All Models ---\n",
        "loaded_models = {}\n",
        "print(\"Starting to pre-load all models...\")\n",
        "for model_name, model_path in MODELS_TO_TEST.items():\n",
        "    print(f\"\\n--- Loading {model_name}... ---\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        loaded_models[model_name] = {\"model\": model, \"tokenizer\": tokenizer}\n",
        "        print(f\"✅ {model_name} loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ FAILED to load {model_name}. Error: {e}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\nAll available models are pre-loaded.\\n\" + \"=\"*50)\n"
      ],
      "metadata": {
        "id": "VHbEjB0WzUI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Prompts**"
      ],
      "metadata": {
        "id": "UL9-d1C7-ipu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_PROMPTS = {\n",
        "    \"Python: Bubble Sort\": \"Write a Python function to sort a list of numbers using the bubble sort algorithm.\",\n",
        "    \"Python: FastAPI Endpoint\": \"Create a simple FastAPI endpoint in Python that returns a JSON object with the message 'Hello, World!'.\",\n",
        "    \"JavaScript: Fetch API\": \"Write a JavaScript function that uses the Fetch API to get data from 'https://api.example.com/data' and logs it to the console.\",\n",
        "    \"HTML/CSS: Login Form\": \"Generate the HTML and CSS for a simple, centered login form with fields for username, password, and a submit button.\",\n",
        "    \"SQL: Select Employees\": \"Write a SQL query to select the 'name' and 'salary' of all employees from the 'employees' table who work in the 'Engineering' department and have a salary greater than 80000.\",\n",
        "    \"Python: Pandas DataFrame\": \"Write a Python script using pandas to create a DataFrame with columns 'Name' and 'Age', add three rows of data, and then print the DataFrame.\",\n",
        "    \"Python: Class for a Car\": \"Create a Python class named 'Car' with a constructor that accepts 'make', 'model', and 'year'. Include a method that returns a formatted string like '2023 Toyota Camry'.\",\n",
        "    \"Regex: Validate Email\": \"Provide a regular expression in Python to validate an email address.\",\n",
        "    \"Docker: Python App\": \"Write a simple Dockerfile to containerize a Python application that has its dependencies in a requirements.txt file.\",\n",
        "    \"Data Science: Plot with Matplotlib\": \"Generate Python code using Matplotlib to plot a simple sine wave from 0 to 2*pi.\"\n",
        "}"
      ],
      "metadata": {
        "id": "DCQ93RBQtUxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UI #1 - Benchmark All Models**"
      ],
      "metadata": {
        "id": "GC9xPn3I_YBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_inspect_ui():\n",
        "    model_checkboxes = [widgets.Checkbox(value=True, description=name) for name in MODEL_IDS]\n",
        "    prompt_dropdown = widgets.Dropdown(options=SAMPLE_PROMPTS, description='Prompt:')\n",
        "    go_btn = widgets.Button(description='Generate Code')\n",
        "    out_box = widgets.Output()\n",
        "\n",
        "    def on_generate_clicked(b):\n",
        "        with out_box:\n",
        "            clear_output()\n",
        "            selected = [box.description for box in model_checkboxes if box.value]\n",
        "            results = evaluate_models(selected, [prompt_dropdown.value])\n",
        "            for model in selected:\n",
        "                res = results[model][0]\n",
        "                print(f\"Model: {model}\")\n",
        "                print(f\"Generated Code:\\n{res['code']}\\n\")\n",
        "                print(f\"Complexity: {res['complexity']}, Maintainability: {res['maintainability']}, LOC: {res['loc']}\\n\")\n",
        "\n",
        "    go_btn.on_click(on_generate_clicked)\n",
        "\n",
        "    ui = widgets.VBox(model_checkboxes + [prompt_dropdown, go_btn, out_box])\n",
        "    display(ui)"
      ],
      "metadata": {
        "id": "mXQgzADF18Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UI #2 - Inspect Models with Checkboxes**"
      ],
      "metadata": {
        "id": "-e4gGp_g_6RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_inspect_ui():\n",
        "    model_checkboxes = [widgets.Checkbox(value=True, description=name) for name in MODELS_TO_TEST]\n",
        "    prompt_dropdown = widgets.Dropdown(options=SAMPLE_PROMPTS, description='Prompt:')\n",
        "    go_btn = widgets.Button(description='Generate Code')\n",
        "    out_box = widgets.Output()\n",
        "    def on_generate_clicked(b):\n",
        "        with out_box:\n",
        "            clear_output()\n",
        "            selected = [box.description for box in model_checkboxes if box.value]\n",
        "            results = evaluate_models(selected, [prompt_dropdown.value])\n",
        "            for model in selected:\n",
        "                res = results[model][0]\n",
        "                print(f\"Model: {model}\\nGenerated Code:\\n{res['code']}\\n\")\n",
        "                print(f\"Complexity: {res['complexity']}, Maintainability: {res['maintainability']}, LOC: {res['loc']}, Gen Time: {res['gen_time']}s\\n\")\n",
        "    go_btn.on_click(on_generate_clicked)\n",
        "    ui = widgets.VBox(model_checkboxes + [prompt_dropdown, go_btn, out_box])\n",
        "    display(ui)"
      ],
      "metadata": {
        "id": "UzbLZgU0_fqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "q5XVFrWVA_Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_metrics(results):\n",
        "    models = list(results.keys())\n",
        "    complexity = []\n",
        "    maintainability = []\n",
        "    loc = []\n",
        "    for model in models:\n",
        "        c = [x['complexity'] for x in results[model] if x['complexity'] is not None]\n",
        "        m = [x['maintainability'] for x in results[model] if x['maintainability'] is not None]\n",
        "        l = [x['loc'] for x in results[model] if x['loc'] is not None]\n",
        "        complexity.append(sum(c)/len(c) if c else 0)\n",
        "        maintainability.append(sum(m)/len(m) if m else 0)\n",
        "        loc.append(sum(l)/len(l) if l else 0)\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    axs[0].bar(models, complexity); axs[0].set_title(\"Avg Complexity\")\n",
        "    axs[1].bar(models, maintainability); axs[1].set_title(\"Avg Maintainability\")\n",
        "    axs[2].bar(models, loc); axs[2].set_title(\"Avg LOC\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CHrW6ETKAD5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1hH6DXEBF0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}